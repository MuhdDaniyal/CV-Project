{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForImageTextToText\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"IAMJB/chexpert-mimic-cxr-impression-baseline\")\n",
    "model = AutoModelForImageTextToText.from_pretrained(\"IAMJB/chexpert-mimic-cxr-impression-baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below 2 cells are rough work (ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    outputs = model.generate(**inputs)\n",
    "\n",
    "# Decode the generated text (this is a text-to-text model)\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Output (Impression or Caption):\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "outputs = model.generate(**inputs)\n",
    "\n",
    "# Decode the generated text (this is a text-to-text model)\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Output (Impression or Caption):\", generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First model (chexpert-mimic-cxr-impression-baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForImageTextToText\n",
    "from PIL import Image\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load the image (make sure you have an X-ray image file)\n",
    "image_path = \"/kaggle/input/iu-xray/WhatsApp Image 2024-12-10 at 03.08.25_2bf725f3.jpg\"  # Replace with the path to your X-ray image\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Resize and normalize the image (you can check the model's documentation for specific requirements)\n",
    "image = image.convert(\"RGB\")  # Ensure image is in RGB format\n",
    "image = image.resize((224, 224))  # Example resize to match model input size (check the model's input size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "\n",
    "# Use an appropriate image processor (if available for the model)\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"IAMJB/chexpert-mimic-cxr-impression-baseline\")\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(images=image, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Forward pass to get the model output\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    outputs = model.generate(**inputs)\n",
    "\n",
    "# Decode the generated text (this is a text-to-text model)\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Output (Impression or Caption):\", generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Generated Output (Impression or Caption): 1. no acute cardiopulmonary process. 2. no evidence of free air beneath the diaphragms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now for next image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "image_path = \"/kaggle/input/iu-xray/WhatsApp Image 2024-12-10 at 03.08.25_a9d6bb87.jpg\"  # Replace with the path to your X-ray image\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Resize and normalize the image (you can check the model's documentation for specific requirements)\n",
    "image = image.convert(\"RGB\")  # Ensure image is in RGB format\n",
    "image = image.resize((224, 224))  # Example resize to match model input size (check the model's input size)\n",
    "\n",
    "# Use an appropriate image processor (if available for the model)\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"IAMJB/chexpert-mimic-cxr-impression-baseline\")\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "# Forward pass to get the model output\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    outputs = model.generate(**inputs)\n",
    "\n",
    "# Decode the generated text (this is a text-to-text model)\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Output (Impression or Caption):\", generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "image_path = \"/kaggle/input/iu-xray/WhatsApp Image 2024-12-10 at 03.08.25_a9d6bb87.jpg\"  # Replace with the path to your X-ray image\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Resize and normalize the image (you can check the model's documentation for specific requirements)\n",
    "image = image.convert(\"RGB\")  # Ensure image is in RGB format\n",
    "image = image.resize((224, 224))  # Example resize to match model input size (check the model's input size)\n",
    "\n",
    "# Use an appropriate image processor (if available for the model)\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"IAMJB/chexpert-mimic-cxr-impression-baseline\")\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "# Forward pass to get the model output\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    outputs = model.generate(**inputs, max_length=100,num_beams=5,       # Beam search for better quality\n",
    "    temperature=0.7,   # Lower temperature for more deterministic output\n",
    "    top_p=0.9)\n",
    "\n",
    "# Decode the generated text (this is a text-to-text model)\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Output (Impression or Caption):\", generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# doesnt do any changes in output so i will not do any parameter changes below if you want to do then do otherwise i don't think so there is any need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now for next model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForImageTextToText\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"IAMJB/chexpert-impression-baseline\")\n",
    "model = AutoModelForImageTextToText.from_pretrained(\"IAMJB/chexpert-impression-baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "image_path = \"/kaggle/input/iu-xray/WhatsApp Image 2024-12-10 at 03.08.25_2bf725f3.jpg\"  # Replace with the path to your X-ray image\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Resize and normalize the image (you can check the model's documentation for specific requirements)\n",
    "image = image.convert(\"RGB\")  # Ensure image is in RGB format\n",
    "image = image.resize((224, 224))  # Example resize to match model input size (check the model's input size)\n",
    "\n",
    "# Use an appropriate image processor (if available for the model)\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"IAMJB/chexpert-impression-baseline\")\n",
    "\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "# Forward pass to get the model output\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    outputs = model.generate(**inputs)\n",
    "\n",
    "# Decode the generated text (this is a text-to-text model)\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Output (Impression or Caption):\", generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "image_path = \"/kaggle/input/iu-xray/WhatsApp Image 2024-12-10 at 03.08.25_a9d6bb87.jpg\"  # Replace with the path to your X-ray image\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Resize and normalize the image (you can check the model's documentation for specific requirements)\n",
    "image = image.convert(\"RGB\")  # Ensure image is in RGB format\n",
    "image = image.resize((224, 224))  # Example resize to match model input size (check the model's input size)\n",
    "\n",
    "# Use an appropriate image processor (if available for the model)\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"IAMJB/chexpert-impression-baseline\")\n",
    "\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "# Forward pass to get the model output\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    outputs = model.generate(**inputs)\n",
    "\n",
    "# Decode the generated text (this is a text-to-text model)\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Output (Impression or Caption):\", generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now for next model (Findings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForImageTextToText\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"IAMJB/chexpert-mimic-cxr-findings-baseline\")\n",
    "model = AutoModelForImageTextToText.from_pretrained(\"IAMJB/chexpert-mimic-cxr-findings-baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "image_path = \"/kaggle/input/iu-xray/WhatsApp Image 2024-12-10 at 03.08.25_2bf725f3.jpg\"  # Replace with the path to your X-ray image\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Resize and normalize the image (you can check the model's documentation for specific requirements)\n",
    "image = image.convert(\"RGB\")  # Ensure image is in RGB format\n",
    "image = image.resize((224, 224))  # Example resize to match model input size (check the model's input size)\n",
    "\n",
    "# Use an appropriate image processor (if available for the model)\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"IAMJB/chexpert-mimic-cxr-findings-baseline\")\n",
    "\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "# Forward pass to get the model output\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    outputs = model.generate(**inputs)\n",
    "\n",
    "# Decode the generated text (this is a text-to-text model)\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Output (Impression or Caption):\", generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "image_path = \"/kaggle/input/iu-xray/WhatsApp Image 2024-12-10 at 03.08.25_a9d6bb87.jpg\"  # Replace with the path to your X-ray image\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Resize and normalize the image (you can check the model's documentation for specific requirements)\n",
    "image = image.convert(\"RGB\")  # Ensure image is in RGB format\n",
    "image = image.resize((224, 224))  # Example resize to match model input size (check the model's input size)\n",
    "\n",
    "# Use an appropriate image processor (if available for the model)\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"IAMJB/chexpert-mimic-cxr-findings-baseline\")\n",
    "\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "# Forward pass to get the model output\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    outputs = model.generate(**inputs)\n",
    "\n",
    "# Decode the generated text (this is a text-to-text model)\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Output (Impression or Caption):\", generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Details of outputs[1]:\", outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Model (BLIP finetuned for chest xray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"daniyal214/finetuned-blip-chest-xrays\")\n",
    "model = AutoModelForImageTextToText.from_pretrained(\"daniyal214/finetuned-blip-chest-xrays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "image_path = \"/kaggle/input/iu-xray/WhatsApp Image 2024-12-10 at 03.08.25_2bf725f3.jpg\"  # Replace with the path to your X-ray image\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Resize and normalize the image (you can check the model's documentation for specific requirements)\n",
    "image = image.convert(\"RGB\")  # Ensure image is in RGB format\n",
    "image = image.resize((224, 224))  # Example resize to match model input size (check the model's input size)\n",
    "\n",
    "# Use an appropriate image processor (if available for the model)\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"daniyal214/finetuned-blip-chest-xrays\")\n",
    "\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "# Forward pass to get the model output\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    outputs = model.generate(**inputs)\n",
    "\n",
    "# Decode the generated text (this is a text-to-text model)\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Output (Impression or Caption):\", generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "image_path = \"/kaggle/input/iu-xray/WhatsApp Image 2024-12-10 at 03.08.25_a9d6bb87.jpg\"  # Replace with the path to your X-ray image\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Resize and normalize the image (you can check the model's documentation for specific requirements)\n",
    "image = image.convert(\"RGB\")  # Ensure image is in RGB format\n",
    "image = image.resize((224, 224))  # Example resize to match model input size (check the model's input size)\n",
    "\n",
    "# Use an appropriate image processor (if available for the model)\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"daniyal214/finetuned-blip-chest-xrays\")\n",
    "\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "# Forward pass to get the model output\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    outputs = model.generate(**inputs)\n",
    "\n",
    "# Decode the generated text (this is a text-to-text model)\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Output (Impression or Caption):\", generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ye wala tou kaam nhi kr raha pata nhi kia bol raha hai xD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
